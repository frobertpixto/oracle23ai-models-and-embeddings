{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761fd728-b45c-4c9e-80a4-a26872a6798e",
   "metadata": {},
   "source": [
    "# Collaborative Filtering recommender model using full 32M Movieslens Dataset\n",
    "- Using Tensorflow\n",
    "- Model is then saved in ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:09.723607Z",
     "start_time": "2025-06-18T15:35:09.720725Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# TensorFlow\n",
    "from tf_keras.models import Model, load_model\n",
    "from tf_keras.layers import Input, Embedding, Dot, Reshape, Dropout\n",
    "from tf_keras.optimizers import Adam\n",
    "from tf_keras.optimizers.legacy import Adam  # For mac M1/M2\n",
    "from tf_keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddf6d74c0852232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:09.753778Z",
     "start_time": "2025-06-18T15:35:09.751963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.12\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b11c30be8e9c142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:09.786128Z",
     "start_time": "2025-06-18T15:35:09.784330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde4269c0e738d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:09.819333Z",
     "start_time": "2025-06-18T15:35:09.817281Z"
    }
   },
   "outputs": [],
   "source": [
    "BASEDIR = \"..\"\n",
    "MODEL_DIR      = os.path.join(BASEDIR, \"saved_models\")\n",
    "model_filename = os.path.join(MODEL_DIR, \"collaboration_filter.01.keras\")\n",
    "\n",
    "# Create Model directory\n",
    "Path(MODEL_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12691a7244923666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:09.849568Z",
     "start_time": "2025-06-18T15:35:09.847540Z"
    }
   },
   "outputs": [],
   "source": [
    "movielens_dataset = \"full\" # \"full\" #\"small\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41707560-2cc6-4299-8345-ff4a3e10e57d",
   "metadata": {},
   "source": [
    "## Step 1.1: Load the Dataset (ratings.csv)\n",
    "The full dataset has more than 32 million ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac94dda68a153d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:14.540083Z",
     "start_time": "2025-06-18T15:35:09.876960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ratings.csv...\n",
      "Loaded 32000204 ratings.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading ratings.csv...\")\n",
    "try:\n",
    "    df_ratings = pd.read_csv(f'../../movielens_data/{movielens_dataset}/ratings.csv')\n",
    "    print(f\"Loaded {len(df_ratings)} ratings.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ratings.csv not found. Please place it in the same directory.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e458923-98ca-4493-a675-2d008b71c0d8",
   "metadata": {},
   "source": [
    "## Step 1.2: Create Mappings for User and Movie IDs \n",
    "We need to convert the arbitrary user and movie IDs into a continuous 0-based index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bf5e915b6c069b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:14.804687Z",
     "start_time": "2025-06-18T15:35:14.572221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created user and movie ID mappings.\n",
      "User map sample: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n",
      "Movie map sample: {17: 0, 25: 1, 29: 2, 30: 3, 32: 4}\n"
     ]
    }
   ],
   "source": [
    "# Get all unique user and movie IDs\n",
    "unique_user_ids = df_ratings['userId'].unique()\n",
    "unique_movie_ids = df_ratings['movieId'].unique()\n",
    "\n",
    "# Create a mapping from userId to a new 0-based index (user_idx)\n",
    "user_map = {id: i for i, id in enumerate(unique_user_ids)}\n",
    "# Create a mapping from movieId to a new 0-based index (movie_idx)\n",
    "movie_map = {id: i for i, id in enumerate(unique_movie_ids)}\n",
    "\n",
    "print(\"\\nCreated user and movie ID mappings.\")\n",
    "# Example: See what the first few user IDs map to\n",
    "print(\"User map sample:\", {k: user_map[k] for k in list(user_map)[:5]})\n",
    "# Example: See what the first few movies IDs map to\n",
    "print(\"Movie map sample:\", {k: movie_map[k] for k in list(movie_map)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f371077b-d357-41db-9218-83a5277187ba",
   "metadata": {},
   "source": [
    "## Step 1.3: Apply Mappings to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1678722b5b9ba09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.391200Z",
     "start_time": "2025-06-18T15:35:14.809259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied mappings to create new 'user_idx' and 'movie_idx' columns.\n",
      "\n",
      "DataFrame head with new index columns:\n",
      "   userId  movieId  rating  timestamp  user_idx  movie_idx\n",
      "0       1       17     4.0  944249077         0          0\n",
      "1       1       25     1.0  944250228         0          1\n",
      "2       1       29     2.0  943230976         0          2\n",
      "3       1       30     5.0  944249077         0          3\n",
      "4       1       32     5.0  943228858         0          4\n"
     ]
    }
   ],
   "source": [
    "# Create new columns in the DataFrame that contain the 0-based indices.\n",
    "df_ratings['user_idx'] = df_ratings['userId'].map(user_map)\n",
    "df_ratings['movie_idx'] = df_ratings['movieId'].map(movie_map)\n",
    "\n",
    "print(\"Applied mappings to create new 'user_idx' and 'movie_idx' columns.\")\n",
    "print(\"\\nDataFrame head with new index columns:\")\n",
    "print(df_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95bb5b-1a2d-48fe-af2b-78dfdb16bce7",
   "metadata": {},
   "source": [
    "## Step 1.4: Prepare the Final Data for TensorFlow\n",
    "We now have everything we need to create our input and output arrays for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ee2a5619cb0f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.463498Z",
     "start_time": "2025-06-18T15:35:15.447159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique users: 200948\n",
      "Total unique movies: 84432\n",
      "\n",
      "Data is now prepared for TensorFlow model training.\n",
      "Shape of x[0] (user_idx): (32000204,)\n",
      "Shape of x[1] (movie_idx): (32000204,)\n",
      "Shape of y (ratings): (32000204,)\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of unique users and movies. This is our \"vocabulary size\".\n",
    "num_users = len(user_map)\n",
    "num_movies = len(movie_map)\n",
    "print(f\"\\nTotal unique users: {num_users}\")\n",
    "print(f\"Total unique movies: {num_movies}\")\n",
    "\n",
    "# Prepare the input 'x' (a list of two arrays: user indices and movie indices)\n",
    "x = [df_ratings['user_idx'].values, df_ratings['movie_idx'].values]\n",
    "\n",
    "# Prepare the output 'y' (the ratings)\n",
    "y = df_ratings['rating'].values\n",
    "\n",
    "print(\"\\nData is now prepared for TensorFlow model training.\")\n",
    "print(f\"Shape of x[0] (user_idx): {x[0].shape}\")\n",
    "print(f\"Shape of x[1] (movie_idx): {x[1].shape}\")\n",
    "print(f\"Shape of y (ratings): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7be59-2bd4-4332-bfd6-9a56be1fbd20",
   "metadata": {},
   "source": [
    "## Step 2.1: Define Model Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f0d67a8b4d2895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.494206Z",
     "start_time": "2025-06-18T15:35:15.492411Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define the size of our embedding vectors.\n",
    "# This is a key parameter to tune. It also directly impact the size of the model\n",
    "EMBEDDING_DIM = 64\n",
    "\n",
    "DROPOUT = 0.15\n",
    "\n",
    "LEARNING_RATE = 0.0014\n",
    "\n",
    "BATCH_SIZE = 16384\n",
    "\n",
    "EPOCH = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b6f73-add5-4370-9cff-52b924933df4",
   "metadata": {},
   "source": [
    "## Step 2.2: Define the Model Architecture using Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bd40d5667a4839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.543090Z",
     "start_time": "2025-06-18T15:35:15.522229Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 17:41:57.829381: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-07-01 17:41:57.829410: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-07-01 17:41:57.829415: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2025-07-01 17:41:57.829432: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-01 17:41:57.829441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Define the input layers for user and movie indices\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "# --- User Pathway ---\n",
    "# 1. User Embedding Layer: Turns the user index into a dense vector\n",
    "user_embedding = Embedding(input_dim=num_users,\n",
    "                           output_dim=EMBEDDING_DIM,\n",
    "                           name='user_embedding')(user_input)\n",
    "# 2. Reshape the embedding to remove the extra dimension\n",
    "user_vector = Reshape((EMBEDDING_DIM,), name='user_vector')(user_embedding)\n",
    "user_vector = Dropout(DROPOUT, name='user_dropout')(user_vector)\n",
    "\n",
    "# --- Movie Pathway ---\n",
    "# 1. Movie Embedding Layer: Turns the movie index into a dense vector\n",
    "movie_embedding = Embedding(input_dim=num_movies,\n",
    "                            output_dim=EMBEDDING_DIM,\n",
    "                            name='movie_embedding')(movie_input)\n",
    "# 2. Reshape the embedding to remove the extra dimension\n",
    "movie_vector = Reshape((EMBEDDING_DIM,), name='movie_vector')(movie_embedding)\n",
    "movie_vector = Dropout(DROPOUT, name='movie_dropout')(movie_vector)\n",
    "\n",
    "\n",
    "# --- Combine the pathways ---\n",
    "# Use a Dot product to calculate the core interaction between user and movie vectors\n",
    "dot_product = Dot(axes=1, name='dot_product')([user_vector, movie_vector])\n",
    "\n",
    "\n",
    "# --- Create and Compile the Model ---\n",
    "# The model takes the user and movie inputs and outputs the dot product result\n",
    "model = Model(inputs=[user_input, movie_input], outputs=dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f1e00b0ac187e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.624194Z",
     "start_time": "2025-06-18T15:35:15.571929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model with an optimizer and a loss function\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50499c-76d0-4070-a169-248a71afb3cc",
   "metadata": {},
   "source": [
    "## Step 2.3: Display the Model Summary\n",
    "This gives a nice overview of the model architecture and number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c29f692deef2d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.666528Z",
     "start_time": "2025-06-18T15:35:15.657598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " movie_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 64)                1286067   ['user_input[0][0]']          \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding  (None, 1, 64)                5403648   ['movie_input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " user_vector (Reshape)       (None, 64)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " movie_vector (Reshape)      (None, 64)                   0         ['movie_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " user_dropout (Dropout)      (None, 64)                   0         ['user_vector[0][0]']         \n",
      "                                                                                                  \n",
      " movie_dropout (Dropout)     (None, 64)                   0         ['movie_vector[0][0]']        \n",
      "                                                                                                  \n",
      " dot_product (Dot)           (None, 1)                    0         ['user_dropout[0][0]',        \n",
      "                                                                     'movie_dropout[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18264320 (69.67 MB)\n",
      "Trainable params: 18264320 (69.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08afa2f-bb83-4ebc-8ad7-a34fca43d5da",
   "metadata": {},
   "source": [
    "### Note on Model size\n",
    "**18 millions parameters** is small compared to a llama 70 billions parameters.\n",
    "But it is very big compared to the 4 models I used in my app [Mix on Pix](https://apps.apple.com/us/app/mix-on-pix-text-on-photos/id633281586). \n",
    "They had 0.5 millions parameters each (but they run locally on an iPhone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6d71ba94bcad8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.708613Z",
     "start_time": "2025-06-18T15:35:15.706492Z"
    }
   },
   "outputs": [],
   "source": [
    "# when running for many epochs, the reduction must be very slow.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.70,\n",
    "                                            mode='min',\n",
    "                                            min_delta=0.000001,\n",
    "                                            min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe48a1ecd91682b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:15.738136Z",
     "start_time": "2025-06-18T15:35:15.736314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the Best model\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [checkpoint, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac517ff5-3c78-42fa-aef6-d19474391735",
   "metadata": {},
   "source": [
    "## Step 3.1: Create Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c19face70c7ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:53.265627Z",
     "start_time": "2025-06-18T15:35:15.765324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and validation sets:\n",
      "Training samples: 28800183\n",
      "Validation samples: 3200021\n"
     ]
    }
   ],
   "source": [
    "# We use scikit-learn's train_test_split to randomly shuffle and split our data.\n",
    "# We'll use 90% for training and 10% for validation.\n",
    "(train_users, val_users,\n",
    " train_movies, val_movies,\n",
    " train_ratings, val_ratings) = train_test_split(x[0], x[1], y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Data split into training and validation sets:\")\n",
    "print(f\"Training samples: {len(train_users)}\")\n",
    "print(f\"Validation samples: {len(val_users)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe85615-9e1c-4883-9604-3c5ff96e26c7",
   "metadata": {},
   "source": [
    "## Step 3.2: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c35f99c-34f8-4904-b50a-4a0864db441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 17:42:06.308948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758/1758 [==============================] - ETA: 0s - loss: 3.3391\n",
      "Epoch 1: val_loss improved from inf to 0.81515, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 48s 23ms/step - loss: 3.3391 - val_loss: 0.8151 - lr: 0.0014\n",
      "Epoch 2/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.8531\n",
      "Epoch 2: val_loss improved from 0.81515 to 0.72816, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 21ms/step - loss: 0.8531 - val_loss: 0.7282 - lr: 0.0014\n",
      "Epoch 3/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7969\n",
      "Epoch 3: val_loss improved from 0.72816 to 0.69338, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7969 - val_loss: 0.6934 - lr: 0.0014\n",
      "Epoch 4/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7659\n",
      "Epoch 4: val_loss improved from 0.69338 to 0.66966, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7659 - val_loss: 0.6697 - lr: 0.0014\n",
      "Epoch 5/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7437\n",
      "Epoch 5: val_loss improved from 0.66966 to 0.65320, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7437 - val_loss: 0.6532 - lr: 0.0014\n",
      "Epoch 6/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7264\n",
      "Epoch 6: val_loss improved from 0.65320 to 0.64088, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7264 - val_loss: 0.6409 - lr: 0.0014\n",
      "Epoch 7/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7128\n",
      "Epoch 7: val_loss improved from 0.64088 to 0.63192, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7128 - val_loss: 0.6319 - lr: 0.0014\n",
      "Epoch 8/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.7014\n",
      "Epoch 8: val_loss improved from 0.63192 to 0.62539, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.7014 - val_loss: 0.6254 - lr: 0.0014\n",
      "Epoch 9/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6917\n",
      "Epoch 9: val_loss improved from 0.62539 to 0.62021, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6917 - val_loss: 0.6202 - lr: 0.0014\n",
      "Epoch 10/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6833\n",
      "Epoch 10: val_loss improved from 0.62021 to 0.61606, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 21ms/step - loss: 0.6833 - val_loss: 0.6161 - lr: 0.0014\n",
      "Epoch 11/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6759\n",
      "Epoch 11: val_loss improved from 0.61606 to 0.61277, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6759 - val_loss: 0.6128 - lr: 0.0014\n",
      "Epoch 12/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6693\n",
      "Epoch 12: val_loss improved from 0.61277 to 0.61070, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6693 - val_loss: 0.6107 - lr: 0.0014\n",
      "Epoch 13/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6638\n",
      "Epoch 13: val_loss improved from 0.61070 to 0.60864, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6638 - val_loss: 0.6086 - lr: 0.0014\n",
      "Epoch 14/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6590\n",
      "Epoch 14: val_loss improved from 0.60864 to 0.60727, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6590 - val_loss: 0.6073 - lr: 0.0014\n",
      "Epoch 15/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6546\n",
      "Epoch 15: val_loss improved from 0.60727 to 0.60608, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6546 - val_loss: 0.6061 - lr: 0.0014\n",
      "Epoch 16/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6507\n",
      "Epoch 16: val_loss improved from 0.60608 to 0.60535, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6507 - val_loss: 0.6053 - lr: 0.0014\n",
      "Epoch 17/60\n",
      "1757/1758 [============================>.] - ETA: 0s - loss: 0.6474\n",
      "Epoch 17: val_loss improved from 0.60535 to 0.60428, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6474 - val_loss: 0.6043 - lr: 0.0014\n",
      "Epoch 18/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6443\n",
      "Epoch 18: val_loss improved from 0.60428 to 0.60379, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6443 - val_loss: 0.6038 - lr: 0.0014\n",
      "Epoch 19/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6420\n",
      "Epoch 19: val_loss improved from 0.60379 to 0.60332, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6420 - val_loss: 0.6033 - lr: 0.0014\n",
      "Epoch 20/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6396\n",
      "Epoch 20: val_loss improved from 0.60332 to 0.60326, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6396 - val_loss: 0.6033 - lr: 0.0014\n",
      "Epoch 21/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6375\n",
      "Epoch 21: val_loss improved from 0.60326 to 0.60289, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6375 - val_loss: 0.6029 - lr: 0.0014\n",
      "Epoch 22/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6359\n",
      "Epoch 22: val_loss improved from 0.60289 to 0.60254, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6359 - val_loss: 0.6025 - lr: 0.0014\n",
      "Epoch 23/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6341\n",
      "Epoch 23: val_loss improved from 0.60254 to 0.60214, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6341 - val_loss: 0.6021 - lr: 0.0014\n",
      "Epoch 24/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6324\n",
      "Epoch 24: val_loss improved from 0.60214 to 0.60156, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6324 - val_loss: 0.6016 - lr: 0.0014\n",
      "Epoch 25/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6315\n",
      "Epoch 25: val_loss did not improve from 0.60156\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6315 - val_loss: 0.6017 - lr: 0.0014\n",
      "Epoch 26/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6302\n",
      "Epoch 26: val_loss did not improve from 0.60156\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.000979999965056777.\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6302 - val_loss: 0.6018 - lr: 0.0014\n",
      "Epoch 27/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6189\n",
      "Epoch 27: val_loss improved from 0.60156 to 0.59431, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6189 - val_loss: 0.5943 - lr: 9.8000e-04\n",
      "Epoch 28/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6162\n",
      "Epoch 28: val_loss improved from 0.59431 to 0.59368, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6162 - val_loss: 0.5937 - lr: 9.8000e-04\n",
      "Epoch 29/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6149\n",
      "Epoch 29: val_loss improved from 0.59368 to 0.59348, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6149 - val_loss: 0.5935 - lr: 9.8000e-04\n",
      "Epoch 30/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6137\n",
      "Epoch 30: val_loss improved from 0.59348 to 0.59339, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6137 - val_loss: 0.5934 - lr: 9.8000e-04\n",
      "Epoch 31/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6129\n",
      "Epoch 31: val_loss improved from 0.59339 to 0.59315, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 36s 20ms/step - loss: 0.6129 - val_loss: 0.5931 - lr: 9.8000e-04\n",
      "Epoch 32/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6121\n",
      "Epoch 32: val_loss improved from 0.59315 to 0.59304, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6121 - val_loss: 0.5930 - lr: 9.8000e-04\n",
      "Epoch 33/60\n",
      "1756/1758 [============================>.] - ETA: 0s - loss: 0.6114\n",
      "Epoch 33: val_loss improved from 0.59304 to 0.59296, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6114 - val_loss: 0.5930 - lr: 9.8000e-04\n",
      "Epoch 34/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6111\n",
      "Epoch 34: val_loss did not improve from 0.59296\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6111 - val_loss: 0.5930 - lr: 9.8000e-04\n",
      "Epoch 35/60\n",
      "1756/1758 [============================>.] - ETA: 0s - loss: 0.6100\n",
      "Epoch 35: val_loss improved from 0.59296 to 0.59272, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6100 - val_loss: 0.5927 - lr: 9.8000e-04\n",
      "Epoch 36/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6099\n",
      "Epoch 36: val_loss improved from 0.59272 to 0.59253, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6099 - val_loss: 0.5925 - lr: 9.8000e-04\n",
      "Epoch 37/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6094\n",
      "Epoch 37: val_loss did not improve from 0.59253\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6094 - val_loss: 0.5925 - lr: 9.8000e-04\n",
      "Epoch 38/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6088\n",
      "Epoch 38: val_loss did not improve from 0.59253\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006860000081360339.\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6088 - val_loss: 0.5926 - lr: 9.8000e-04\n",
      "Epoch 39/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6016\n",
      "Epoch 39: val_loss improved from 0.59253 to 0.58800, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6016 - val_loss: 0.5880 - lr: 6.8600e-04\n",
      "Epoch 40/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.6003\n",
      "Epoch 40: val_loss improved from 0.58800 to 0.58782, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.6003 - val_loss: 0.5878 - lr: 6.8600e-04\n",
      "Epoch 41/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5993\n",
      "Epoch 41: val_loss improved from 0.58782 to 0.58756, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5993 - val_loss: 0.5876 - lr: 6.8600e-04\n",
      "Epoch 42/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5989\n",
      "Epoch 42: val_loss improved from 0.58756 to 0.58739, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5989 - val_loss: 0.5874 - lr: 6.8600e-04\n",
      "Epoch 43/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5984\n",
      "Epoch 43: val_loss improved from 0.58739 to 0.58705, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5984 - val_loss: 0.5871 - lr: 6.8600e-04\n",
      "Epoch 44/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5980\n",
      "Epoch 44: val_loss did not improve from 0.58705\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5980 - val_loss: 0.5872 - lr: 6.8600e-04\n",
      "Epoch 45/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5976\n",
      "Epoch 45: val_loss did not improve from 0.58705\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0004801999893970787.\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5976 - val_loss: 0.5871 - lr: 6.8600e-04\n",
      "Epoch 46/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5928\n",
      "Epoch 46: val_loss improved from 0.58705 to 0.58421, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5928 - val_loss: 0.5842 - lr: 4.8020e-04\n",
      "Epoch 47/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5916\n",
      "Epoch 47: val_loss improved from 0.58421 to 0.58385, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5916 - val_loss: 0.5838 - lr: 4.8020e-04\n",
      "Epoch 48/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5913\n",
      "Epoch 48: val_loss did not improve from 0.58385\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5913 - val_loss: 0.5840 - lr: 4.8020e-04\n",
      "Epoch 49/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5909\n",
      "Epoch 49: val_loss improved from 0.58385 to 0.58379, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5909 - val_loss: 0.5838 - lr: 4.8020e-04\n",
      "Epoch 50/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5904\n",
      "Epoch 50: val_loss improved from 0.58379 to 0.58361, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5904 - val_loss: 0.5836 - lr: 4.8020e-04\n",
      "Epoch 51/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5904\n",
      "Epoch 51: val_loss improved from 0.58361 to 0.58352, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5904 - val_loss: 0.5835 - lr: 4.8020e-04\n",
      "Epoch 52/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5900\n",
      "Epoch 52: val_loss improved from 0.58352 to 0.58344, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5900 - val_loss: 0.5834 - lr: 4.8020e-04\n",
      "Epoch 53/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5897\n",
      "Epoch 53: val_loss improved from 0.58344 to 0.58340, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5897 - val_loss: 0.5834 - lr: 4.8020e-04\n",
      "Epoch 54/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5895\n",
      "Epoch 54: val_loss did not improve from 0.58340\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5895 - val_loss: 0.5834 - lr: 4.8020e-04\n",
      "Epoch 55/60\n",
      "1756/1758 [============================>.] - ETA: 0s - loss: 0.5891\n",
      "Epoch 55: val_loss did not improve from 0.58340\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0003361399925779551.\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5891 - val_loss: 0.5834 - lr: 4.8020e-04\n",
      "Epoch 56/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5858\n",
      "Epoch 56: val_loss improved from 0.58340 to 0.58145, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5858 - val_loss: 0.5814 - lr: 3.3614e-04\n",
      "Epoch 57/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5854\n",
      "Epoch 57: val_loss improved from 0.58145 to 0.58125, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5854 - val_loss: 0.5812 - lr: 3.3614e-04\n",
      "Epoch 58/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5849\n",
      "Epoch 58: val_loss did not improve from 0.58125\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5849 - val_loss: 0.5813 - lr: 3.3614e-04\n",
      "Epoch 59/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5847\n",
      "Epoch 59: val_loss improved from 0.58125 to 0.58117, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5847 - val_loss: 0.5812 - lr: 3.3614e-04\n",
      "Epoch 60/60\n",
      "1758/1758 [==============================] - ETA: 0s - loss: 0.5845\n",
      "Epoch 60: val_loss improved from 0.58117 to 0.58097, saving model to ../saved_models/collaboration_filter.01.keras\n",
      "1758/1758 [==============================] - 35s 20ms/step - loss: 0.5845 - val_loss: 0.5810 - lr: 3.3614e-04\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Now we call model.fit() to start the training process.\n",
    "print(\"\\nStarting model training...\")\n",
    "history = model.fit(\n",
    "    # Input data for training\n",
    "    x=[train_users, train_movies],\n",
    "    # Target data for training\n",
    "    y=train_ratings,\n",
    "    # Number of samples per gradient update\n",
    "    batch_size=BATCH_SIZE,  \n",
    "    # Number of times to iterate over the entire training dataset\n",
    "    epochs=EPOCH,\n",
    "    # Display training progress\n",
    "    verbose=1,\n",
    "    # Data to evaluate the model on at the end of each epoch\n",
    "    validation_data=([val_users, val_movies], val_ratings),\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705cec2-d836-4219-b990-688623b936bf",
   "metadata": {},
   "source": [
    "## Step 3.3: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7318c52914574db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:53.372659Z",
     "start_time": "2025-06-18T16:29:53.313506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The 'history' object contains the loss values from training.\n",
    "# We can plot them to see how the model learned over time.\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs - Log scale')\n",
    "plt.ylabel('Loss (Mean Squared Error)')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750f7f33dd5b0cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:53.836741Z",
     "start_time": "2025-06-18T16:29:53.403095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the existing model\n",
    "del model\n",
    "\n",
    "# Load last saved model\n",
    "model = load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de78b2f8df39f9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:53.873222Z",
     "start_time": "2025-06-18T16:29:53.864660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our learned movie embedding matrix: (84432, 64)\n"
     ]
    }
   ],
   "source": [
    "# 'model' is our trained Keras model\n",
    "# We get the layer by its name, then get its learned weights.\n",
    "# get_weights() returns a list, the first item is the embedding matrix.\n",
    "movie_embedding_matrix = model.get_layer('movie_embedding').get_weights()[0]\n",
    "\n",
    "print(f\"Shape of our learned movie embedding matrix: {movie_embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464cb21f7924a5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:54.064241Z",
     "start_time": "2025-06-18T16:29:53.901123Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# We need the mappings from our data prep step to go from title -> ID -> index\n",
    "# user_map, movie_map\n",
    "# We also need a reverse mapping from index back to title\n",
    "# Let's create a DataFrame with movie titles and their learned indices\n",
    "df_movies = pd.read_csv(f'../../movielens_data/{movielens_dataset}/movies.csv')\n",
    "df_movies['movie_idx'] = df_movies['movieId'].map(movie_map)\n",
    "# Drop movies that were not in our ratings dataset\n",
    "df_movies = df_movies.dropna(subset=['movie_idx'])\n",
    "df_movies['movie_idx'] = df_movies['movie_idx'].astype(int)\n",
    "\n",
    "# Create the reverse map from index to title\n",
    "idx_to_title = df_movies.set_index('movie_idx')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42885eeec2cc61a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:54.102620Z",
     "start_time": "2025-06-18T16:29:54.099326Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_movies(movie_title, top_n=10):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given movie using the learned embeddings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Get the movie_idx for the given title\n",
    "        movie_idx = df_movies[df_movies['title'] == movie_title]['movie_idx'].iloc[0]\n",
    "\n",
    "        # 2. Get the embedding vector for that movie\n",
    "        movie_vector = movie_embedding_matrix[movie_idx]\n",
    "\n",
    "        # 3. Calculate cosine similarity between that vector and all others\n",
    "        # We reshape our vector to (1, EMBEDDING_DIM) to make it a 2D array\n",
    "        sim_scores = cosine_similarity(movie_vector.reshape(1, -1), movie_embedding_matrix)\n",
    "\n",
    "        # 4. Get the similarity scores for all movies and sort them\n",
    "        # sim_scores is a 2D array, so we take the first row\n",
    "        sim_scores = list(enumerate(sim_scores[0]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 5. Get the top N results, excluding the movie itself\n",
    "        top_similar_movies = [\n",
    "            (idx_to_title.get(i, \"Unknown\"), score)\n",
    "            for i, score in sim_scores[1:top_n + 1]\n",
    "        ]\n",
    "\n",
    "        print(f\"Top {top_n} movies similar to '{movie_title}':\")\n",
    "        for title, score in top_similar_movies:\n",
    "            print(f\"  - {title} (Similarity: {score:.4f})\")\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b278d65e40693f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:54.466575Z",
     "start_time": "2025-06-18T16:29:54.138813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies similar to 'Apocalypse Now (1979)':\n",
      "  - Taxi Driver (1976) (Similarity: 0.9375)\n",
      "  - Full Metal Jacket (1987) (Similarity: 0.9316)\n",
      "  - Deer Hunter, The (1978) (Similarity: 0.9226)\n",
      "  - Raging Bull (1980) (Similarity: 0.9062)\n",
      "  - Chinatown (1974) (Similarity: 0.9013)\n",
      "  - Platoon (1986) (Similarity: 0.8915)\n",
      "  - Mariupolis (2016) (Similarity: 0.8914)\n",
      "  - Modus Operandi (2010) (Similarity: 0.8877)\n",
      "  - My Best Friend's Famous (2019) (Similarity: 0.8849)\n",
      "  - No Country for Old Men (2007) (Similarity: 0.8763)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Arrival (2016)':\n",
      "  - Ex Machina (2015) (Similarity: 0.9000)\n",
      "  - Moon (2009) (Similarity: 0.8620)\n",
      "  - LIFE BEYOND: Chapter 2. The Museum of Alien Life (2020) (Similarity: 0.8548)\n",
      "  - Pornography: A Secret History of Civilisation (1999) (Similarity: 0.8531)\n",
      "  - Coherence (2013) (Similarity: 0.8520)\n",
      "  - The Martian (2015) (Similarity: 0.8514)\n",
      "  - Annihilation (2018) (Similarity: 0.8511)\n",
      "  - Crimes Against Humanity (2017) (Similarity: 0.8510)\n",
      "  - One I Love, The (2014) (Similarity: 0.8504)\n",
      "  - Mully (2015) (Similarity: 0.8474)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Inception (2010)':\n",
      "  - Prestige, The (2006) (Similarity: 0.8982)\n",
      "  - Interstellar (2014) (Similarity: 0.8943)\n",
      "  - Shutter Island (2010) (Similarity: 0.8841)\n",
      "  - Join or Die (2023) (Similarity: 0.8667)\n",
      "  - Guilty Conscience (1985) (Similarity: 0.8542)\n",
      "  - Rascals on the Road (2006) (Similarity: 0.8506)\n",
      "  - Departed, The (2006) (Similarity: 0.8502)\n",
      "  - The Penalty (1941) (Similarity: 0.8490)\n",
      "  - Catch Me If You Can (2002) (Similarity: 0.8482)\n",
      "  - Memento (2000) (Similarity: 0.8470)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'My Life as a Dog (Mitt liv som hund) (1985)':\n",
      "  - Breaking Away (1979) (Similarity: 0.8569)\n",
      "  - The Race to Alaska (2020) (Similarity: 0.8562)\n",
      "  - Saturday Morning Mystery (2012) (Similarity: 0.8515)\n",
      "  - My Brother's Keeper (2014) (Similarity: 0.8511)\n",
      "  - Head-On (Gegen die Wand) (2004) (Similarity: 0.8496)\n",
      "  - The Magnitude of All Things (2020) (Similarity: 0.8486)\n",
      "  - Eat Drink Man Woman (Yin shi nan nu) (1994) (Similarity: 0.8484)\n",
      "  - Megan (2020) (Similarity: 0.8479)\n",
      "  - Waltz with Bashir (Vals im Bashir) (2008) (Similarity: 0.8465)\n",
      "  - Attention danger travail (2003) (Similarity: 0.8427)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Other Guys, The (2010)':\n",
      "  - Talladega Nights: The Ballad of Ricky Bobby (2006) (Similarity: 0.8890)\n",
      "  - Role Models (2008) (Similarity: 0.8745)\n",
      "  - Campaign, The (2012) (Similarity: 0.8685)\n",
      "  - Dodgeball: A True Underdog Story (2004) (Similarity: 0.8660)\n",
      "  - 21 Jump Street (2012) (Similarity: 0.8613)\n",
      "  - Due Date (2010) (Similarity: 0.8584)\n",
      "  - Horrible Bosses (2011) (Similarity: 0.8575)\n",
      "  - 22 Jump Street (2014) (Similarity: 0.8508)\n",
      "  - Tropic Thunder (2008) (Similarity: 0.8480)\n",
      "  - Step Brothers (2008) (Similarity: 0.8403)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Let's test it! ---\n",
    "find_similar_movies('Apocalypse Now (1979)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Arrival (2016)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Inception (2010)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('My Life as a Dog (Mitt liv som hund) (1985)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Other Guys, The (2010)')\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca7edb1064fc5e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:29:54.588475Z",
     "start_time": "2025-06-18T16:29:54.567279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies similar to 'Toy Story (1995)':\n",
      "  - Toy Story 2 (1999) (Similarity: 0.9840)\n",
      "  - Toy Story 3 (2010) (Similarity: 0.9478)\n",
      "  - Monsters, Inc. (2001) (Similarity: 0.9352)\n",
      "  - Finding Nemo (2003) (Similarity: 0.9252)\n",
      "  - Bug's Life, A (1998) (Similarity: 0.9225)\n",
      "  - Incredibles, The (2004) (Similarity: 0.9064)\n",
      "  - Iron Giant, The (1999) (Similarity: 0.8575)\n",
      "  - Up (2009) (Similarity: 0.8526)\n",
      "  - Toy Story 4 (2019) (Similarity: 0.8508)\n",
      "  - Wreck-It Ralph (2012) (Similarity: 0.8503)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Parenthood (1989)':\n",
      "  - Mr. Mom (1983) (Similarity: 0.8905)\n",
      "  - Stand by Me (1986) (Similarity: 0.8730)\n",
      "  - Big (1988) (Similarity: 0.8717)\n",
      "  - Midnight Run (1988) (Similarity: 0.8703)\n",
      "  - No Way Out (1987) (Similarity: 0.8668)\n",
      "  - Biloxi Blues (1988) (Similarity: 0.8623)\n",
      "  - Moonlight Sonata: Deafness in Three Movements (2019) (Similarity: 0.8612)\n",
      "  - Trading Places (1983) (Similarity: 0.8582)\n",
      "  - Lady Beware (1987) (Similarity: 0.8572)\n",
      "  - Homeless: The Motel Kids of Orange County (2010) (Similarity: 0.8566)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Eyes Wide Shut (1999)':\n",
      "  - Barry Lyndon (1975) (Similarity: 0.8168)\n",
      "  - The Case of the Lucky Legs (1935) (Similarity: 0.7934)\n",
      "  - The Young Observant (2020) (Similarity: 0.7907)\n",
      "  - Mulholland Drive (2001) (Similarity: 0.7870)\n",
      "  - Lost Highway (1997) (Similarity: 0.7807)\n",
      "  - Mulholland Dr. (1999) (Similarity: 0.7804)\n",
      "  - Happy Hour (2015) (Similarity: 0.7801)\n",
      "  - Study of a River (1997) (Similarity: 0.7759)\n",
      "  - The Laughing Man (1966) (Similarity: 0.7722)\n",
      "  - The Animation Show, Volume 1 (2003) (Similarity: 0.7715)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Thirteenth Floor, The (1999)':\n",
      "  - 10th & Wolf (2006) (Similarity: 0.8437)\n",
      "  - Valley of the Wolves: Palestine (2011) (Similarity: 0.8092)\n",
      "  - Gattaca (1997) (Similarity: 0.8082)\n",
      "  - Paycheck (2003) (Similarity: 0.8075)\n",
      "  - Another Woman (2019) (Similarity: 0.8041)\n",
      "  - Fly (2021) (Similarity: 0.8017)\n",
      "  - Sofia the First: Once Upon a Princess (2012) (Similarity: 0.8011)\n",
      "  - The Diam Diam Era (2020) (Similarity: 0.7974)\n",
      "  - İstanbul Beneath My Wings (1996) (Similarity: 0.7942)\n",
      "  - Impostor (2002) (Similarity: 0.7940)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Little Miss Sunshine (2006)':\n",
      "  - Juno (2007) (Similarity: 0.9018)\n",
      "  - The Swimmers (2014) (Similarity: 0.8894)\n",
      "  - Station Agent, The (2003) (Similarity: 0.8784)\n",
      "  - Lars and the Real Girl (2007) (Similarity: 0.8780)\n",
      "  - The Playbirds (1978) (Similarity: 0.8775)\n",
      "  - Dunkles, rätselhaftes Österreich (Similarity: 0.8753)\n",
      "  - Away We Go (2009) (Similarity: 0.8722)\n",
      "  - Good bye, Lenin! (2003) (Similarity: 0.8698)\n",
      "  - Human (2013) (Similarity: 0.8595)\n",
      "  - Education, An (2009) (Similarity: 0.8567)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Finding Nemo (2003)':\n",
      "  - Monsters, Inc. (2001) (Similarity: 0.9783)\n",
      "  - Incredibles, The (2004) (Similarity: 0.9376)\n",
      "  - Bug's Life, A (1998) (Similarity: 0.9279)\n",
      "  - Ratatouille (2007) (Similarity: 0.9267)\n",
      "  - Up (2009) (Similarity: 0.9264)\n",
      "  - Toy Story (1995) (Similarity: 0.9252)\n",
      "  - Toy Story 2 (1999) (Similarity: 0.9195)\n",
      "  - Toy Story 3 (2010) (Similarity: 0.9097)\n",
      "  - Monsters University (2013) (Similarity: 0.8784)\n",
      "  - Shrek (2001) (Similarity: 0.8783)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Wild (2016)':\n",
      "  - Wedding in Galilee (1988) (Similarity: 0.9150)\n",
      "  - Jadoo (2013) (Similarity: 0.8952)\n",
      "  - The Invention of Love (2013) (Similarity: 0.8882)\n",
      "  - Hey... Stop Stabbing Me! (2003) (Similarity: 0.8865)\n",
      "  - Cirque du Soleil: Saltimbanco (1997) (Similarity: 0.8860)\n",
      "  - Die Bettwurst (1971) (Similarity: 0.8859)\n",
      "  - Bruges-La-Morte (1978) (Similarity: 0.8835)\n",
      "  - Judge Fayard Called the Sheriff (1977) (Similarity: 0.8821)\n",
      "  - Alien Girl (2010) (Similarity: 0.8814)\n",
      "  - The Legend of the Red Lantern (1970) (Similarity: 0.8795)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Hidden Figures (2016)':\n",
      "  - Help, The (2011) (Similarity: 0.9192)\n",
      "  - On the Basis of Sex (2018) (Similarity: 0.8921)\n",
      "  - Woman in Gold (2015) (Similarity: 0.8779)\n",
      "  - The Theory of Everything (2014) (Similarity: 0.8760)\n",
      "  - The Imitation Game (2014) (Similarity: 0.8747)\n",
      "  - Sully (2016) (Similarity: 0.8745)\n",
      "  - Invictus (2009) (Similarity: 0.8701)\n",
      "  - Lion (2016) (Similarity: 0.8694)\n",
      "  - Just Mercy (2019) (Similarity: 0.8676)\n",
      "  - Still Alice (2014) (Similarity: 0.8652)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Before Midnight (2013)':\n",
      "  - Before Sunset (2004) (Similarity: 0.9572)\n",
      "  - Before Sunrise (1995) (Similarity: 0.9443)\n",
      "  - Death of a Father (2017) (Similarity: 0.8430)\n",
      "  - Forgotten Plague (2016) (Similarity: 0.8371)\n",
      "  - Bert Rigby, You're a Fool (1989) (Similarity: 0.8320)\n",
      "  - Scenes From a Marriage (Scener ur ett äktenskap) (1973) (Similarity: 0.8312)\n",
      "  - Hunt, The (Jagten) (2012) (Similarity: 0.8309)\n",
      "  - The Guard from the Underground (1992) (Similarity: 0.8280)\n",
      "  - My Uncle Hyacinth (1956) (Similarity: 0.8276)\n",
      "  - Diving Bell and the Butterfly, The (Scaphandre et le papillon, Le) (2007) (Similarity: 0.8275)\n",
      "------------------------------\n",
      "Top 10 movies similar to 'Begin Again (2013)':\n",
      "  - Shoot To Marry (2020) (Similarity: 0.8854)\n",
      "  - The Wedding Trip (2021) (Similarity: 0.8812)\n",
      "  - Memory Hackers (2016) (Similarity: 0.8812)\n",
      "  - The Fundamentals of Caring (2016) (Similarity: 0.8803)\n",
      "  - A Night at the Kindergarten (2022) (Similarity: 0.8801)\n",
      "  - Chef (2014) (Similarity: 0.8794)\n",
      "  - Whip It (2009) (Similarity: 0.8791)\n",
      "  - In His Chart (2011) (Similarity: 0.8781)\n",
      "  - Sparrow (1993) (Similarity: 0.8762)\n",
      "  - The Devotion of Suspect X (2017) (2017) (Similarity: 0.8734)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- More tests ---\n",
    "find_similar_movies('Toy Story (1995)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Parenthood (1989)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Eyes Wide Shut (1999)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Thirteenth Floor, The (1999)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Little Miss Sunshine (2006)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Finding Nemo (2003)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Wild (2016)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Hidden Figures (2016)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Before Midnight (2013)')\n",
    "print(\"-\" * 30)\n",
    "find_similar_movies('Begin Again (2013)')\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0dbf2-f42c-490b-9607-f3b6628fc709",
   "metadata": {},
   "source": [
    "## Step 4 - Create an ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26ea71a9-8431-4f4a-91f1-058fd6a94e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19b6c179-2b19-4123-997a-c544ab99bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_OUTPUT_FILE = os.path.join(MODEL_DIR, \"cf_recommender.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f885cc7-e440-4c2e-b73b-276bf0dbb661",
   "metadata": {},
   "source": [
    "## Step 4.1: Define the Input Signature for our Multi-Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea08def-156e-46d4-b340-160d2eed721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the input signature for ONNX conversion...\n",
      "Input signature defined:\n",
      "  - Input 1: name='user_input', shape=(None, 1), dtype=int32\n",
      "  - Input 2: name='movie_input', shape=(None, 1), dtype=int32\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining the input signature for ONNX conversion...\")\n",
    "\n",
    "# Our model has two inputs (the user and the movie), so our signature will be a tuple of two TensorSpecs.\n",
    "# The `name` in each TensorSpec MUST match the name of the Input layer in your Keras model.\n",
    "# The shape [None, 1] means the model can accept batches of any size (None), where each input is a single value (1).\n",
    "input_signature = (\n",
    "    tf.TensorSpec([None, 1], tf.int32, name='user_input'),\n",
    "    tf.TensorSpec([None, 1], tf.int32, name='movie_input')\n",
    ")\n",
    "\n",
    "print(\"Input signature defined:\")\n",
    "print(f\"  - Input 1: name='{input_signature[0].name}', shape={input_signature[0].shape}, dtype={input_signature[0].dtype.name}\")\n",
    "print(f\"  - Input 2: name='{input_signature[1].name}', shape={input_signature[1].shape}, dtype={input_signature[1].dtype.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92e111-5bdf-442f-9b7a-41bd1deb4cb6",
   "metadata": {},
   "source": [
    "## Step 4.2: Convert the Model to ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f11b61f9-4d2d-4b96-8ea5-85d110d3ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting model to ONNX with opset 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 18:58:29.332728: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-07-01 18:58:29.333445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-01 18:58:29.333453: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-07-01 18:58:29.681108: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-01 18:58:29.681133: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-07-01 18:58:29.747978: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-07-01 18:58:29.748144: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-01 18:58:29.748153: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# The opset version is important. 13 or 15 are good, stable choices.\n",
    "print(f\"\\nConverting model to ONNX with opset 15...\")\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=input_signature,\n",
    "    opset=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9d980bd-b3a5-4676-81a9-3e1918b7f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Model successfully converted and saved to:\n",
      "  ../saved_models/cf_recommender.onnx\n"
     ]
    }
   ],
   "source": [
    "# Save the ONNX model to a file\n",
    "onnx.save(onnx_model, ONNX_OUTPUT_FILE)\n",
    "\n",
    "print(f\"SUCCESS: Model successfully converted and saved to:\")\n",
    "print(f\"  {ONNX_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a954d9-5ba0-4f2d-bb6f-f6cd9dbf6f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
